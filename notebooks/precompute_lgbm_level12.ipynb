{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/turing/miniconda/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from tsforest.forecaster import LightGBMForecaster\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# local modules\n",
    "import sys\n",
    "sys.path.append(\"../lib/\")\n",
    "from utils import reduce_mem_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (pd.read_parquet(\"../input/train_dataframe.parquet\")\n",
    "        .reset_index(drop=True)\n",
    "        .rename({\"q\":\"y\"}, axis=1)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45942500 entries, 0 to 45942499\n",
      "Data columns (total 35 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   ts_id              int16         \n",
      " 1   item_id            int16         \n",
      " 2   dept_id            int8          \n",
      " 3   cat_id             int8          \n",
      " 4   store_id           int8          \n",
      " 5   state_id           int8          \n",
      " 6   y                  int16         \n",
      " 7   ds                 datetime64[ns]\n",
      " 8   event_name_1       int8          \n",
      " 9   event_type_1       int8          \n",
      " 10  event_name_2       int8          \n",
      " 11  event_type_2       int8          \n",
      " 12  sell_price         float32       \n",
      " 13  n_prices           float32       \n",
      " 14  regular_price      float32       \n",
      " 15  price_iqr1         float32       \n",
      " 16  price_iqr2         float32       \n",
      " 17  price_min          float32       \n",
      " 18  price_max          float32       \n",
      " 19  discount           float32       \n",
      " 20  discount_norm      float32       \n",
      " 21  price_momentum_m   float32       \n",
      " 22  price_momentum_y   float32       \n",
      " 23  prev_christmas     int8          \n",
      " 24  post_christmas     int8          \n",
      " 25  prev_newyear       int8          \n",
      " 26  post_newyear       int8          \n",
      " 27  prev_thanksgiving  int8          \n",
      " 28  post_thanksgiving  int8          \n",
      " 29  lw_type            int8          \n",
      " 30  lw_day             int8          \n",
      " 31  prev_lw            int8          \n",
      " 32  post_lw            int8          \n",
      " 33  snap               int8          \n",
      " 34  no_stock           int8          \n",
      "dtypes: datetime64[ns](1), float32(11), int16(3), int8(20)\n",
      "memory usage: 3.3 GB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "validation periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_valid_periods(end_date, valid_length, n_folds):\n",
    "    right_date = pd.to_datetime(end_date)\n",
    "    valid_periods = list()\n",
    "    \n",
    "    for i in range(n_folds):\n",
    "        left_date = right_date - pd.DateOffset(days=valid_length-1)\n",
    "        valid_periods.append((left_date, right_date))\n",
    "        right_date = left_date - pd.DateOffset(days=1)\n",
    "    \n",
    "    return valid_periods[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Timestamp('2015-04-25 00:00:00'), Timestamp('2015-05-22 00:00:00')),\n",
       " (Timestamp('2015-05-23 00:00:00'), Timestamp('2015-06-19 00:00:00'))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_periods = [(pd.to_datetime(\"2015-04-25\"), pd.to_datetime(\"2015-05-22\")),\n",
    "                 (pd.to_datetime(\"2015-05-23\"), pd.to_datetime(\"2015-06-19\")),\n",
    "                 #(pd.to_datetime(\"2016-02-29\"), pd.to_datetime(\"2016-03-27\")),\n",
    "                 #(pd.to_datetime(\"2016-03-28\"), pd.to_datetime(\"2016-04-24\"))\n",
    "                ]\n",
    "valid_periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "building the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 years of history\n",
    "train_history = 1095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = [\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"year_week\",\n",
    "    \"week_day\",\n",
    "    \"month_progress\"]\n",
    "\n",
    "exclude_features = [\"ts_id\",\n",
    "                    \"event_type_1\",\n",
    "                    \"event_name_2\",\n",
    "                    \"event_type_2\",\n",
    "                    \"prev_christmas\",\n",
    "                    \"post_christmas\",\n",
    "                    \"prev_newyear\",\n",
    "                    \"post_newyear\",\n",
    "                    \"prev_thanksgiving\",\n",
    "                    \"post_thanksgiving\"]\n",
    "\n",
    "model_kwargs = {\n",
    "    \"time_features\":time_features,\n",
    "    \"lags\": list(range(1,15)),\n",
    "    \"window_shifts\":[1,7,28],\n",
    "    \"window_functions\":[\"mean\",\"std\"],\n",
    "    \"window_sizes\":[7,28],    \n",
    "    \"exclude_features\":exclude_features,\n",
    "    \"categorical_features\":{#\"ts_id\":\"default\",\n",
    "                            \"item_id\":\"default\", \n",
    "                            \"dept_id\":\"default\",\n",
    "                            \"cat_id\":\"default\",\n",
    "                            \"store_id\":\"default\",\n",
    "                            \"state_id\":\"default\",\n",
    "                            \"event_name_1\":\"default\", \n",
    "                            \"snap\":\"default\"},\n",
    "    \"ts_uid_columns\":[\"item_id\",\"store_id\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################### 1/2 ################################################\n",
      "##### Validation period: (Timestamp('2015-04-25 00:00:00'), Timestamp('2015-05-22 00:00:00')) ######\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i,valid_period in enumerate(valid_periods):\n",
    "    print(f\" {i+1}/{len(valid_periods)} \".center(100, \"#\"))\n",
    "    print(f\" Validation period: {valid_period} \".center(100, \"#\"))\n",
    "    print(\"#\"*100)\n",
    "    \n",
    "    valid_start = valid_period[0]\n",
    "    valid_end = valid_period[1]\n",
    "    train_start = valid_start - pd.DateOffset(days=train_history)\n",
    "        \n",
    "    _train_data = data.query(\"ds <= @valid_end\").reset_index(drop=True)\n",
    "    _valid_index = _train_data.query(\"@valid_start <= ds <= @valid_end\").index\n",
    "\n",
    "    _fcaster = LightGBMForecaster(**model_kwargs)\n",
    "    _fcaster.prepare_features(train_data=_train_data, valid_index=_valid_index);\n",
    "    \n",
    "    _fcaster.train_features.dropna(inplace=True)\n",
    "    _fcaster.train_features = _fcaster.train_features.query(\"ds >= @train_start\")\n",
    "    _fcaster.train_data = _fcaster.train_data.query(\"ds >= @train_start\")\n",
    "    _fcaster.train_features = reduce_mem_usage(_fcaster.train_features)\n",
    "    _fcaster.valid_features = reduce_mem_usage(_fcaster.valid_features)\n",
    "\n",
    "    ts_in_both = pd.merge(_fcaster.train_features.loc[:, [\"store_id\",\"item_id\"]].drop_duplicates(),\n",
    "                          _fcaster.valid_features.loc[:, [\"store_id\",\"item_id\"]].drop_duplicates(),\n",
    "                          how=\"inner\")\n",
    "    _fcaster.train_features = pd.merge(_fcaster.train_features, ts_in_both, how=\"inner\")\n",
    "    _fcaster.valid_features = pd.merge(_fcaster.valid_features, ts_in_both, how=\"inner\")\n",
    "\n",
    "    # needed to remove leakage of 'no_stock' feature\n",
    "    no_stock_ts = list()\n",
    "    for threshold in [28, 56, 84, 112, 140, 168]:\n",
    "        left_date = _fcaster.train_features.ds.max() - pd.DateOffset(days=threshold)\n",
    "        no_stock_ts.append((_fcaster.train_features\n",
    "                            .query(\"ds >= @left_date\")\n",
    "                            .groupby([\"ts_id\"])\n",
    "                            .filter(lambda x: np.all(x.q==0))\n",
    "                            .loc[:, [\"ts_id\"]]\n",
    "                            .drop_duplicates()))\n",
    "        \n",
    "    _fcaster.valid_features[\"no_stock\"] = 0\n",
    "    for i,no_stock in enumerate(no_stock_ts):\n",
    "        idx = _fcaster.valid_features.query(\"ts_id in @no_stock.ts_id\").index\n",
    "        _fcaster.valid_features.loc[idx, \"no_stock\"] = i+1\n",
    "    \n",
    "    \n",
    "    with open(f\"../precomputed/model{i}.pickle\", \"wb\") as handler:\n",
    "        pickle.dump(_fcaster, handler, protocol=4)\n",
    "        handler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
