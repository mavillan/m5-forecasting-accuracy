{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/turing/miniconda/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import numpy as np; np.random.seed(42)\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tsforest.trend import compute_trend_models\n",
    "from tsforest.forecaster import LightGBMForecaster\n",
    "from tsforest.utils import make_time_range\n",
    "from tsforest.metrics import compute_rmse\n",
    "\n",
    "# local modules\n",
    "import sys\n",
    "sys.path.append(\"../lib/\")\n",
    "from utils import compute_scaling, compute_weights, reduce_mem_usage\n",
    "from evaluation import _WRMSSEEvaluator, WRMSSEEvaluator, Evaluator\n",
    "\n",
    "def trimean(array, axis=0):\n",
    "    quantiles = np.percentile(array, [25, 50, 75], axis=axis)\n",
    "    return (quantiles[0,:] + 2*quantiles[1,:] + quantiles[2,:])/4\n",
    "\n",
    "SEEDS = [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation period to be used for test in all this notebook\n",
    "valid_period = (pd.to_datetime(\"2016-03-28\"), pd.to_datetime(\"2016-04-24\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Level 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46796220 entries, 0 to 46796219\n",
      "Data columns (total 43 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   ts_id              int16         \n",
      " 1   item_id            int16         \n",
      " 2   dept_id            int8          \n",
      " 3   cat_id             int8          \n",
      " 4   store_id           int8          \n",
      " 5   state_id           int8          \n",
      " 6   y                  int16         \n",
      " 7   ds                 datetime64[ns]\n",
      " 8   snap_CA            int8          \n",
      " 9   snap_TX            int8          \n",
      " 10  snap_WI            int8          \n",
      " 11  snap_CA_cum        int8          \n",
      " 12  snap_TX_cum        int8          \n",
      " 13  snap_WI_cum        int8          \n",
      " 14  event_name_1       int8          \n",
      " 15  event_type_1       int8          \n",
      " 16  event_name_2       int8          \n",
      " 17  event_type_2       int8          \n",
      " 18  sell_price         float32       \n",
      " 19  n_prices           float32       \n",
      " 20  regular_price      float32       \n",
      " 21  price_iqr1         float32       \n",
      " 22  price_iqr2         float32       \n",
      " 23  price_min          float32       \n",
      " 24  price_max          float32       \n",
      " 25  discount           float32       \n",
      " 26  discount_norm      float32       \n",
      " 27  price_momentum_m   float32       \n",
      " 28  price_momentum_q   float32       \n",
      " 29  price_momentum_y   float32       \n",
      " 30  prev_christmas     int8          \n",
      " 31  post_christmas     int8          \n",
      " 32  prev_newyear       int8          \n",
      " 33  post_newyear       int8          \n",
      " 34  prev_thanksgiving  int8          \n",
      " 35  post_thanksgiving  int8          \n",
      " 36  lw_type            int8          \n",
      " 37  lw_day             int8          \n",
      " 38  prev_lw            int8          \n",
      " 39  post_lw            int8          \n",
      " 40  no_stock_days      int16         \n",
      " 41  sales_freq_mean    float32       \n",
      " 42  sales_freq_std     float32       \n",
      "dtypes: datetime64[ns](1), float32(14), int16(4), int8(24)\n",
      "memory usage: 4.2 GB\n"
     ]
    }
   ],
   "source": [
    "data = (pd.read_parquet(\"../input/train_dataframe.parquet\")\n",
    "        .reset_index(drop=True)\n",
    "        .rename({\"q\":\"y\"}, axis=1)\n",
    "       )\n",
    "\n",
    "scaling_input = pd.read_parquet(\"../input/scaling_input.parquet\")\n",
    "weighting_input = pd.read_parquet(\"../input/weighting_input.parquet\")\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales_level12 = compute_scaling(scaling_input, \n",
    "                                 cut_date=valid_period[0],\n",
    "                                 agg_columns=[\"item_id\",\"store_id\"]).rename({\"q\":\"s\"}, axis=1)\n",
    "\n",
    "weights_level12 = compute_weights(weighting_input, \n",
    "                                  start_date=valid_period[0], level=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier removal\n",
    "#remove_idx = data.query(\"ds.dt.month == 12 & ds.dt.day == 25\").index\n",
    "#data.drop(remove_idx, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'objective':'tweedie',\n",
    "    'tweedie_variance_power': 1.1,\n",
    "    'metric':'None',\n",
    "    'num_iterations':100000,\n",
    "    'early_stopping_rounds':300,\n",
    "    'max_bin': 127,\n",
    "    'bin_construct_sample_cnt':6000000,\n",
    "    'num_leaves': 2**10-1,\n",
    "    'min_data_in_leaf': 2**10-1,\n",
    "    'learning_rate': 0.05, \n",
    "    #'min_sum_hessian_in_leaf':1e-4,\n",
    "    'feature_fraction': 0.9,\n",
    "    #'feature_fraction_bynode':0.9,\n",
    "    'bagging_fraction':0.66,\n",
    "    'bagging_freq':1,\n",
    "    'lambda_l2':0.1,\n",
    "    'seed':7,\n",
    "    'boost_from_average': False,\n",
    "    'first_metric_only': True,\n",
    "}\n",
    "\n",
    "time_features = [\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"year_week\",\n",
    "    #\"year_day\",\n",
    "    \"week_day\",\n",
    "    \"month_progress\", \n",
    "    #\"week_day_cos\",\n",
    "    #\"week_day_sin\",\n",
    "    #\"year_day_cos\",\n",
    "    #\"year_day_sin\",\n",
    "    #\"year_week_cos\",\n",
    "    #\"year_week_sin\",\n",
    "    #\"month_cos\",\n",
    "    #\"month_sin\"\n",
    "]\n",
    "\n",
    "exclude_features = [\n",
    "    \"ts_id\",\n",
    "    \"event_type_1\",\n",
    "    \"event_name_2\",\n",
    "    \"event_type_2\",\n",
    "    \"prev_newyear\",\n",
    "    \"post_newyear\",\n",
    "    \"no_stock_days\",\n",
    "]\n",
    "\n",
    "\n",
    "model_kwargs = {\n",
    "    \"model_params\":model_params,\n",
    "    \"time_features\":time_features,\n",
    "    \"window_shifts\":[1,7,28,56],\n",
    "    \"window_functions\":[\"mean\",\"median\",\"std\",\"kurt\",],\n",
    "    \"window_sizes\":[7,28],\n",
    "    \"exclude_features\":exclude_features,\n",
    "    \"categorical_features\":{\"item_id\": \"default\",\n",
    "                            \"store_id\": \"default\",\n",
    "                            \"state_id\": \"default\",\n",
    "                            \"dept_id\": \"default\",\n",
    "                            \"cat_id\": \"default\",\n",
    "                            \"event_name_1\": \"default\",\n",
    "    },\n",
    "    \"ts_uid_columns\":[\"item_id\",\"store_id\"],\n",
    "}\n",
    "\n",
    "lagged_features = list()\n",
    "if \"lags\" in model_kwargs.keys():\n",
    "    lag_features = [f\"lag{lag}\" for lag in model_kwargs[\"lags\"]]\n",
    "    lagged_features.extend(lag_features)\n",
    "if \"window_functions\" in model_kwargs.keys():\n",
    "    rw_features = [f\"{window_func}{window_size}_shift{window_shift}\" \n",
    "                   for window_func in model_kwargs[\"window_functions\"]\n",
    "                   for window_size in model_kwargs[\"window_sizes\"]\n",
    "                   for window_shift in model_kwargs[\"window_shifts\"]]\n",
    "    lagged_features.extend(rw_features)\n",
    "    \n",
    "lagged_features_to_dropna = [feat for feat in lagged_features if feat not in [\"skew\", \"kurt\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sleep 1.5h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"#\"*100)\n",
    "print(f\" Validation period: {valid_period} \".center(100, \"#\"))\n",
    "print(\"#\"*100)\n",
    "\n",
    "valid_start = valid_period[0]\n",
    "valid_end = valid_period[1]\n",
    "_train_data = data.query(\"ds <= @valid_end\").reset_index(drop=True)\n",
    "_valid_index = _train_data.query(\"@valid_start <= ds <= @valid_end\").index\n",
    "\n",
    "model_level12 = LightGBMForecaster(**model_kwargs)\n",
    "model_level12.prepare_features(train_data=_train_data, valid_index=_valid_index);\n",
    "model_level12.train_features.dropna(subset=lagged_features_to_dropna, axis=0, inplace=True)\n",
    "model_level12.train_features = reduce_mem_usage(model_level12.train_features)\n",
    "model_level12.valid_features = reduce_mem_usage(model_level12.valid_features)\n",
    "ts_id_in_train = model_level12.train_features.ts_id.unique()\n",
    "model_level12.valid_features = model_level12.valid_features.query(\"ts_id in @ts_id_in_train\")\n",
    "\n",
    "print(\"Fitting the model\")\n",
    "tic = time.time()\n",
    "evaluator = Evaluator(model_level12.valid_features)\n",
    "model_level12.fit(fit_kwargs={\"verbose_eval\":25, \"feval\":evaluator.evaluate})\n",
    "tac = time.time()\n",
    "print(f\"Elapsed time: {(tac-tic)/60.} [min]\")\n",
    "\n",
    "lgb.plot_importance(model_level12.model.model, importance_type=\"split\", figsize=(10,8))\n",
    "lgb.plot_importance(model_level12.model.model, importance_type=\"gain\", figsize=(10,8))\n",
    "\n",
    "valid_dataframe = (model_level12.valid_features\n",
    "                   .loc[:, [\"ds\",\"item_id\",\"dept_id\",\"cat_id\",\"store_id\",\"state_id\",\"y\"]]\n",
    "                   .copy())\n",
    "evaluator = WRMSSEEvaluator(valid_dataframe)\n",
    "\n",
    "print(\"Predicting with ground thruth lagged values\")\n",
    "tic = time.time()\n",
    "forecast_v0 = (model_level12.valid_features\n",
    "                  .loc[:, [\"ds\"]+model_level12.ts_uid_columns]\n",
    "                  .assign(y_pred = model_level12.model.predict(model_level12.valid_features)))\n",
    "tac = time.time()\n",
    "print(f\"Elapsed time: {(tac-tic)/60.} [min]\")\n",
    "\n",
    "wrmsse = evaluator._evaluate(forecast_v0.y_pred.values)\n",
    "print(\"\\nwrmsse:\", wrmsse)\n",
    "print(evaluator.errors_by_level)\n",
    "\n",
    "print(\"Predicting with recursive approach\")\n",
    "tic = time.time()\n",
    "valid_data = model_level12.valid_features.loc[:, model_level12.raw_train_columns].drop(\"y\", axis=1)\n",
    "forecast_v1 = model_level12.predict(valid_data, recursive=True)\n",
    "tac = time.time()\n",
    "print(f\"Elapsed time: {(tac-tic)/60.} [min]\")\n",
    "\n",
    "wrmsse = evaluator._evaluate(forecast_v1.y_pred.values)\n",
    "print(\"\\nwrmsse:\", wrmsse)\n",
    "print(evaluator.errors_by_level)\n",
    "\n",
    "mrg = (model_level12.valid_features.groupby([\"ds\"])[\"y\"].sum().reset_index()\n",
    "       .merge(forecast_v0.groupby([\"ds\"])[\"y_pred\"].sum().reset_index(), on=\"ds\")\n",
    "       .merge(forecast_v1.groupby([\"ds\"])[\"y_pred\"].sum().reset_index(), on=\"ds\"))\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot_date(mrg.ds, mrg.y, \"o-\", label=\"real\")\n",
    "plt.plot_date(mrg.ds, mrg.y_pred_x, \"o-\", label=\"pred_v0\")\n",
    "plt.plot_date(mrg.ds, mrg.y_pred_y, \"o-\", label=\"pred_v1\")\n",
    "plt.grid()\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
