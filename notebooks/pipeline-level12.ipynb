{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/turing/miniconda/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning:\n",
      "\n",
      "pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import numpy as np; np.random.seed(42)\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tsforest.trend import compute_trend_models\n",
    "from tsforest.forecaster import LightGBMForecaster\n",
    "from tsforest.utils import make_time_range\n",
    "from tsforest.metrics import compute_rmse\n",
    "\n",
    "# local modules\n",
    "import sys\n",
    "sys.path.append(\"../lib/\")\n",
    "from utils import compute_scaling, reduce_mem_usage\n",
    "from evaluation import _WRMSSEEvaluator, WRMSSEEvaluator, Evaluator\n",
    "\n",
    "def trimean(array, axis=0):\n",
    "    quantiles = np.percentile(array, [25, 50, 75], axis=axis)\n",
    "    return (quantiles[0,:] + 2*quantiles[1,:] + quantiles[2,:])/4\n",
    "\n",
    "SEEDS = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = open(f\"../logs/pipeline-level12-{datetime.now()}\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (pd.read_parquet(\"../input/train_dataframe.parquet\")\n",
    "        .reset_index(drop=True)\n",
    "        .rename({\"q\":\"y\"}, axis=1)\n",
    "       )\n",
    "\n",
    "weights_level12 = pd.read_parquet(\"../input/weights_level12.parquet\")\n",
    "scaling_input = pd.read_parquet(\"../input/scaling_input.parquet\")\n",
    "scales_level12 = compute_scaling(scaling_input, agg_columns=[\"item_id\",\"store_id\"]).rename({\"q\":\"s\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46796220 entries, 0 to 46796219\n",
      "Data columns (total 37 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   ts_id              int16         \n",
      " 1   item_id            int16         \n",
      " 2   dept_id            int8          \n",
      " 3   cat_id             int8          \n",
      " 4   store_id           int8          \n",
      " 5   state_id           int8          \n",
      " 6   y                  int16         \n",
      " 7   ds                 datetime64[ns]\n",
      " 8   snap_CA            int8          \n",
      " 9   snap_TX            int8          \n",
      " 10  snap_WI            int8          \n",
      " 11  event_name_1       int8          \n",
      " 12  event_type_1       int8          \n",
      " 13  event_name_2       int8          \n",
      " 14  event_type_2       int8          \n",
      " 15  sell_price         float32       \n",
      " 16  n_prices           float32       \n",
      " 17  regular_price      float32       \n",
      " 18  price_iqr1         float32       \n",
      " 19  price_iqr2         float32       \n",
      " 20  price_min          float32       \n",
      " 21  price_max          float32       \n",
      " 22  discount           float32       \n",
      " 23  discount_norm      float32       \n",
      " 24  price_momentum_m   float32       \n",
      " 25  price_momentum_y   float32       \n",
      " 26  prev_christmas     int8          \n",
      " 27  post_christmas     int8          \n",
      " 28  prev_newyear       int8          \n",
      " 29  post_newyear       int8          \n",
      " 30  prev_thanksgiving  int8          \n",
      " 31  post_thanksgiving  int8          \n",
      " 32  lw_type            int8          \n",
      " 33  lw_day             int8          \n",
      " 34  prev_lw            int8          \n",
      " 35  post_lw            int8          \n",
      " 36  no_stock           int8          \n",
      "dtypes: datetime64[ns](1), float32(11), int16(3), int8(22)\n",
      "memory usage: 3.5 GB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Models configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'objective':'tweedie',\n",
    "    'tweedie_variance_power': 1.1,\n",
    "    'metric':'None',\n",
    "    'num_iterations':100000,\n",
    "    'early_stopping_rounds':200,\n",
    "    'max_bin': 127,\n",
    "    'bin_construct_sample_cnt':6000000,\n",
    "    'num_leaves': 2**10-1,\n",
    "    'min_data_in_leaf': 2**11-1,\n",
    "    'learning_rate': 0.05, \n",
    "    #'min_sum_hessian_in_leaf':1e-4,\n",
    "    'feature_fraction': 0.9,\n",
    "    #'feature_fraction_bynode':0.9,\n",
    "    'bagging_fraction':0.66,\n",
    "    'bagging_freq':1,\n",
    "    'lambda_l2':0.1,\n",
    "    'seed':7,\n",
    "    'boost_from_average': False,\n",
    "    'first_metric_only': True,\n",
    "}\n",
    "\n",
    "time_features = [\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"year_week\",\n",
    "    #\"year_day\",\n",
    "    \"week_day\",\n",
    "    \"month_progress\", \n",
    "    #\"week_day_cos\",\n",
    "    #\"week_day_sin\",\n",
    "    #\"year_day_cos\",\n",
    "    #\"year_day_sin\",\n",
    "    #\"year_week_cos\",\n",
    "    #\"year_week_sin\",\n",
    "    #\"month_cos\",\n",
    "    #\"month_sin\"\n",
    "]\n",
    "\n",
    "exclude_features = [\n",
    "    \"ts_id\",\n",
    "    \"event_type_1\",\n",
    "    \"event_name_2\",\n",
    "    \"event_type_2\"\n",
    "]\n",
    "\n",
    "model_kwargs = {\n",
    "    \"model_params\":model_params,\n",
    "    \"time_features\":time_features,\n",
    "    \"lags\": list(range(1,15)),\n",
    "    \"window_shifts\":[1,7,28],\n",
    "    \"window_functions\":[\"mean\",\"std\",\"kurt\"],\n",
    "    \"window_sizes\":[7,28],\n",
    "    \"exclude_features\":exclude_features,\n",
    "    \"categorical_features\":{#\"ts_id\":\"default\",\n",
    "                            \"item_id\":\"default\", \n",
    "                            \"dept_id\":\"default\",\n",
    "                            \"cat_id\":\"default\",\n",
    "                            \"store_id\":\"default\",\n",
    "                            \"state_id\":\"default\",\n",
    "                            \"event_name_1\":\"default\", \n",
    "                            #\"event_type_1\":\"default\", \n",
    "                            #\"event_name_2\":\"default\", \n",
    "                            #\"event_type_2\":\"default\"\n",
    "    },\n",
    "    \"ts_uid_columns\":[\"item_id\",\"store_id\"]\n",
    "}\n",
    "\n",
    "lag_features = [f\"lag{lag}\" for lag in model_kwargs[\"lags\"]]\n",
    "rw_features = [f\"{window_func}{window_size}_shift{window_shift}\" \n",
    "               for window_func in model_kwargs[\"window_functions\"]\n",
    "               for window_size in model_kwargs[\"window_sizes\"]\n",
    "               for window_shift in model_kwargs[\"window_shifts\"]]\n",
    "lagged_features = lag_features+rw_features\n",
    "lagged_features_to_dropna = [feat for feat in lagged_features if \"kurt\" not in feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.write(\"#\"*100+\"\\n\")\n",
    "logger.write(\" MODEL CONFIGURATION \".center(100, \"#\")+\"\\n\")\n",
    "logger.write(\"#\"*100+\"\\n\\n\")\n",
    "logger.write(f\"- model_params: \\n{model_params}\\n\\n\")\n",
    "logger.write(f\"- time_features: \\n{model_kwargs['time_features']}\\n\\n\")\n",
    "logger.write(f\"- lags: \\n{model_kwargs['lags']}\\n\\n\")\n",
    "logger.write(f\"- window_functions: \\n{model_kwargs['window_functions']}\\n\\n\")\n",
    "logger.write(f\"- window_shifts: \\n{model_kwargs['window_shifts']}\\n\\n\")\n",
    "logger.write(f\"- window_sizes: \\n{model_kwargs['window_sizes']}\\n\\n\")\n",
    "logger.write(f\"- categorical_features: \\n{model_kwargs['categorical_features']}\\n\\n\")\n",
    "logger.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_periods = [\n",
    "    (pd.to_datetime(\"2015-04-25\"), pd.to_datetime(\"2015-05-22\")),\n",
    "    (pd.to_datetime(\"2015-05-23\"), pd.to_datetime(\"2015-06-19\")),\n",
    "    (pd.to_datetime(\"2016-03-28\"), pd.to_datetime(\"2016-04-24\")),\n",
    "    (pd.to_datetime(\"2016-04-25\"), pd.to_datetime(\"2016-05-22\")),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "##### Validation period: (Timestamp('2015-04-25 00:00:00'), Timestamp('2015-05-22 00:00:00')) ######\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "errors_v0 = dict()\n",
    "errors_v1 = dict()\n",
    "\n",
    "def bias_corr_func(x):\n",
    "    x[x < 0.1] = 0\n",
    "    return x\n",
    "\n",
    "for i,valid_period in enumerate(valid_periods):\n",
    "\n",
    "    print(\"#\"*100)\n",
    "    print(f\" Validation period: {valid_period} \".center(100, \"#\"))\n",
    "    print(\"#\"*100)\n",
    "    \n",
    "    logger.write(\"#\"*100 + \"\\n\")\n",
    "    logger.write(f\" Validation period: {valid_period} \".center(100, \"#\") + \"\\n\")\n",
    "    logger.write(\"#\"*100 + \"\\n\\n\")\n",
    "\n",
    "    valid_start = valid_period[0]\n",
    "    valid_end = valid_period[1]\n",
    "    _train_data = data.query(\"ds <= @valid_end\").reset_index(drop=True)\n",
    "    _valid_index = _train_data.query(\"@valid_start <= ds <= @valid_end\").index\n",
    "    \n",
    "    model_level12 = LightGBMForecaster(**model_kwargs)\n",
    "    model_level12.prepare_features(train_data=_train_data, valid_index=_valid_index);\n",
    "    model_level12.train_features.dropna(subset=lagged_features_to_dropna, axis=0, inplace=True)\n",
    "    model_level12.train_features = reduce_mem_usage(model_level12.train_features)\n",
    "    model_level12.valid_features = reduce_mem_usage(model_level12.valid_features)\n",
    "    ts_id_in_train = model_level12.train_features.ts_id.unique()\n",
    "    model_level12.valid_features = model_level12.valid_features.query(\"ts_id in @ts_id_in_train\")\n",
    "\n",
    "    # needed to remove leakage of 'no_stock' feature\n",
    "    no_stock_ts = list()\n",
    "    for threshold in [28, 56, 84, 112, 140, 168]:\n",
    "        left_date = model_level12.train_features.ds.max() - pd.DateOffset(days=threshold)\n",
    "        no_stock_ts.append((model_level12.train_features\n",
    "                            .query(\"ds >= @left_date\")\n",
    "                            .groupby([\"ts_id\"])\n",
    "                            .filter(lambda x: np.all(x.y==0))\n",
    "                            .loc[:, [\"ts_id\"]]\n",
    "                            .drop_duplicates()))\n",
    "    model_level12.valid_features[\"no_stock\"] = 0\n",
    "    for j,no_stock in enumerate(no_stock_ts):\n",
    "        idx = model_level12.valid_features.query(\"ts_id in @no_stock.ts_id\").index\n",
    "        model_level12.valid_features.loc[idx, \"no_stock\"] = j+1\n",
    "        \n",
    "    logger.write(f\"- training samples: {len(fcaster.train_features)} \\n\\n\")\n",
    "    logger.write(f\"- validation samples: {len(fcaster.valid_features)} \\n\\n\")\n",
    "    logger.write(f\"- ts in train set: {fcaster.train_features.ts_id.nunique()} \\n\\n\")\n",
    "    logger.write(f\"- ts in valid set: {fcaster.valid_features.ts_id.nunique()} \\n\\n\")\n",
    "    logger.write(f\"- input_features: {fcaster.input_features} \\n\\n\")\n",
    "    logger.flush()\n",
    "    \n",
    "    print(\"Fitting the model\")\n",
    "    tic = time.time()\n",
    "    evaluator = Evaluator(model_level12.valid_features)\n",
    "    model_level12.fit(fit_kwargs={\"verbose_eval\":25, \"feval\":evaluator.evaluate})\n",
    "    tac = time.time()\n",
    "    print(f\"Elapsed time: {(tac-tic)/60.} [min]\")\n",
    "    \n",
    "    logger.write(f\"- best_iteration: {fcaster.best_iteration} \\n\\n\")\n",
    "    logger.flush()\n",
    "\n",
    "    lgb.plot_importance(model_level12.model.model, importance_type=\"split\", figsize=(10,8))\n",
    "    lgb.plot_importance(model_level12.model.model, importance_type=\"gain\", figsize=(10,8))\n",
    "    \n",
    "    valid_dataframe = (model_level12.valid_features\n",
    "                       .loc[:, [\"ds\",\"item_id\",\"dept_id\",\"cat_id\",\"store_id\",\"state_id\",\"y\"]]\n",
    "                       .copy())\n",
    "    evaluator = WRMSSEEvaluator(valid_dataframe)\n",
    "\n",
    "    print(\"Predicting with ground thruth lagged values\")\n",
    "    tic = time.time()\n",
    "    forecast_f4_v0 = (model_level12.valid_features\n",
    "                      .loc[:, [\"ds\"]+model_level12.ts_uid_columns]\n",
    "                      .assign(y_pred = model_level12.model.predict(model_level12.valid_features)))\n",
    "    tac = time.time()\n",
    "    print(f\"Elapsed time: {(tac-tic)/60.} [min]\")\n",
    "\n",
    "    wrmsse = evaluator._evaluate(forecast_f4_v0.y_pred.values)\n",
    "    errors_v0[f\"f{i}\"] = evaluator.errors_by_level\n",
    "    print(\"wrmsse:\", wrmsse)\n",
    "    print(evaluator.errors_by_level)\n",
    "    \n",
    "    logger.write(f\"- wrmsse approach 1: {wrmsse} \\n\\n\")\n",
    "    logger.write(f\"- all errors approach 1: \\n{evaluator.errors_by_level} \\n\\n\")\n",
    "    logger.flush()\n",
    "\n",
    "    print(\"Predicting with recursive approach\")\n",
    "    tic = time.time()\n",
    "    valid_data = model_level12.valid_features.loc[:, model_level12.raw_train_columns].drop(\"y\", axis=1)\n",
    "    forecast_f4_v1 = model_level12.predict(valid_data, recursive=True, bias_corr_func=bias_corr_func)\n",
    "    tac = time.time()\n",
    "    print(f\"Elapsed time: {(tac-tic)/60.} [min]\")\n",
    "    \n",
    "    wrmsse = evaluator._evaluate(forecast_f4_v1.y_pred.values)\n",
    "    errors_v1[f\"f{i}\"] = evaluator.errors_by_level\n",
    "    print(\"wrmsse:\", wrmsse)\n",
    "    print(evaluator.errors_by_level)\n",
    "    \n",
    "    logger.write(f\"- wrmsse approach 2: {wrmsse} \\n\\n\")\n",
    "    logger.write(f\"- all errors approach 2: \\n{evaluator.errors_by_level} \\n\\n\")\n",
    "    logger.flush()\n",
    "    \n",
    "    mrg = (model_level12.valid_features.groupby([\"ds\"])[\"y\"].sum().reset_index()\n",
    "           .merge(forecast_f4_v0.groupby([\"ds\"])[\"y_pred\"].sum().reset_index(), on=\"ds\")\n",
    "           .merge(forecast_f4_v1.groupby([\"ds\"])[\"y_pred\"].sum().reset_index(), on=\"ds\"))\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot_date(mrg.ds, mrg.y, \"o-\", label=\"real\")\n",
    "    plt.plot_date(mrg.ds, mrg.y_pred_x, \"o-\", label=\"pred_v0\")\n",
    "    plt.plot_date(mrg.ds, mrg.y_pred_y, \"o-\", label=\"pred_v1\")\n",
    "    plt.grid()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "    del model_level12, _train_data, _valid_index\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach1 = [np.mean(list(list(errors_v0.values())[i].values())) for i in range(4)]\n",
    "approach2 = [np.mean(list(list(errors_v1.values())[i].values())) for i in range(4)]\n",
    "\n",
    "logger.write(\"#\"*100 + \"\\n\")\n",
    "logger.write(f\" Overall \".center(100, \"#\") + \"\\n\")\n",
    "logger.write(\"#\"*100 + \"\\n\\n\")\n",
    "\n",
    "logger.write(f\"- approach 1 on all folds: {approach1} - mean: {np.mean(approach1)} \\n\\n\")\n",
    "logger.write(f\"- approach 2 on all folds: {approach2} - mean: {np.mean(approach2)} \\n\\n\")\n",
    "logger.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"- approach 1 on all folds: {approach1} - mean: {np.mean(approach1)}\")\n",
    "print(f\"- approach 2 on all folds: {approach2} - mean: {np.mean(approach2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
